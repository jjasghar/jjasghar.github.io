<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: nagios | jjasghar rants and ramblings]]></title>
  <link href="http://jjasghar.github.io/blog/categories/nagios/atom.xml" rel="self"/>
  <link href="http://jjasghar.github.io/"/>
  <updated>2014-02-07T16:34:40-06:00</updated>
  <id>http://jjasghar.github.io/</id>
  <author>
    <name><![CDATA[JJ Asghar]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Checking CPU WAIT via nagios]]></title>
    <link href="http://jjasghar.github.io/blog/2013/10/16/checking-cpu-wait-via-nagios/"/>
    <updated>2013-10-16T11:11:00-05:00</updated>
    <id>http://jjasghar.github.io/blog/2013/10/16/checking-cpu-wait-via-nagios</id>
    <content type="html"><![CDATA[<p>So our machines swap&hellip;.swap alot. There are the  typical nagios system checks, you can have the <code>check_swap</code> call, but at my company the &lt; 20 % hits so often we needed to figure out a way to get warned about crippling proformance. We discovered that when a machine has CPU WAIT spikes, the proformance for the machine tanks, so I tried to find a check for specificly monitor the CPU WAIT.  I should mention also that most/all of the boxes we run are VMs, and waiting on IO for swap makes a sad sysadmin.</p>

<p>I took a stab at creating a check myself and the following is a simple nagios check that you can run via NRPE.  The <code>PERCENTAGE</code> line is changeable, I&rsquo;d make sure your alarm reflects your error cases. We choose 10 % because that&rsquo;s when we started seeing real prefomance issues, but as all sysadmins know any CPU WAIT is bad in general.</p>

<p>```bash</p>

<h1>!/bin/bash</h1>

<p>stateid=
CPUWAIT=<code>top -b -n 1| grep 'wa,' | awk -F ',' {'print $5'} | cut -d . -f 1 | tr -d ' '</code>
PERCENTAGE=10</p>

<p>if [ ${CPUWAIT} -le ${PERCENTAGE} ]
 then
   echo Your CPU WAIT is under ${PERCENTAGE}%
   stateid=0
elif [ ${CPUWAIT} -ge ${PERCENTAGE} ]
 then
   echo Your CPU WAIT is at ${CPUWAIT}%, your machine aint happy
   stateid=2
 fi
exit $stateid
```</p>

<p>You are probably wondering &ldquo;There are alot of great systems checks on <a href="http://exchange.nagios.org/">Nagios Exchange</a>,&rdquo; but the site is so hard to use and useally much more than I need, like in this case.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to delete the cache in nagios]]></title>
    <link href="http://jjasghar.github.io/blog/2013/10/05/how-to-delete-the-cache-in-nagios/"/>
    <updated>2013-10-05T16:06:00-05:00</updated>
    <id>http://jjasghar.github.io/blog/2013/10/05/how-to-delete-the-cache-in-nagios</id>
    <content type="html"><![CDATA[<p>If you use the <a href="https://github.com/opscode-cookbooks/nagios">nagios cookbook</a>, and you have multiple disposable machines checking in and out of your chef-server, you might notice that running chef-client to pull new machines into nagios doesn&rsquo;t always work.  For a time my company had anything ranging from 4 to 8 machines spinning up and down, so I had to basically run chef-client on a 30 min interval to make sure I got them all. I discovered that my new machines weren&rsquo;t showing up, so I had to figure out how to &ldquo;clear the cache&rdquo; if you will.</p>

<p>Now this this is specific to  the nagios setup I have, but the <code>objects.cache</code> is what controls this.</p>

<p><code>bash
root@boe:/tmp# rm /var/cache/nagios3/objects.cache
root@boe:/tmp# service nagios restart
Running configuration checkâ€¦done.
Stopping nagios: .done.
Starting nagios: done.
root@boe:/tmp# cd /var/cache/nagios3
root@boe:/var/cache/nagios3# ls
objects.cache  status.dat
</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Adventures migrating from 2.4.16 redis to 2.6.16 redis (Part 2)]]></title>
    <link href="http://jjasghar.github.io/blog/2013/10/01/adventures-migrating-from-2-dot-4-16-redis-to-2-dot-6-16-redis-part-2/"/>
    <updated>2013-10-01T18:11:00-05:00</updated>
    <id>http://jjasghar.github.io/blog/2013/10/01/adventures-migrating-from-2-dot-4-16-redis-to-2-dot-6-16-redis-part-2</id>
    <content type="html"><![CDATA[<h1>Monitoring</h1>

<p>Everyone loves monitoring. Ok, that&rsquo;s a lie, only [DevOps|Sysadmins] love monitoring. Ok, that&rsquo;s probably a lie too, hell I love monitoring, and I love nagios.  I&rsquo;ve followed used nagios in some shape or another since nagios-1.0b6. My first real paid job as an &ldquo;IT guy&rdquo; was setting up nagios for a company.  I&rsquo;ve actually gotten in the habit of walking into a new company using <a href="http://jjasghar.github.io/blog/2013/07/12/serverspec-the-new-best-way-to-learn-and-audit-your-infrastructure/">serverspec</a>, to learn what each machine does, then implementing nagios behind the serverspec scripts for a proactive monitoring on error conditions. This might seem redundant, but I don&rsquo;t think so. serverspec is great for spot checking, while nagios gives the best &ldquo;state of the union&rdquo; snapshot. Granted a lot of the time creating these checks are reactive, but sometimes like here, I wrote some proactive monitoring because I know there are certain error conditions on the slaves I&rsquo;ve spun up.</p>

<p>I use nrpe to monitor my machines, and I set up my <code>nrpe.cfg</code> to something like the following. I use chef, so the <code>&lt;%= node['hostname'] %&gt;</code> is from <a href="https://github.com/opscode/ohai">ohai</a>.</p>

<p><code>ini
command[check_redisserver]=/usr/lib/nagios/plugins/check_procs -c 1:1 -C redis-server
command[check_redis_replication]=/usr/lib/nagios/plugins/check_redis_replication -h &lt;%= node['hostname'] %&gt; -w 20 -c 45
command[check_redis_rdb_age]=/usr/lib/nagios/plugins/check_redis_rdb_age &lt;%= node['hostname'] %&gt;
</code></p>

<p>The first line is pretty self explanatory.  Obviously I&rsquo;d like to check that redis is running, and that&rsquo;s what it does.</p>

<p>The second line is where I started creating the new monitoring.  I have all my monitors right now at a 3 strike out rule, I have played with the idea of tweaking it, but it seems 3 strikes then an email seems to cut down on the noise I get.</p>

<p>```ruby</p>

<h1>!/usr/bin/env ruby</h1>

<p>require &lsquo;optparse&rsquo;
options  = {}
required = [:warning, :critical, :host]</p>

<p>parser   = OptionParser.new do |opts|</p>

<pre><code>opts.banner = "Usage: check_redis_replication [options]"
  opts.on("-h", "--host redishost", "The hostname of the redis slave") do |h|
    options[:host] = h
  end
  opts.on("-w", "--warning percentage", "Warning threshold") do |w|
    options[:warning] = w
  end
  opts.on("-c", "--critical critical", "Critical threshold") do |c|
    options[:critical] = c
 end
</code></pre>

<p>end
parser.parse!
abort parser.to_s if !required.all? { |k| options.has_key?(k) }</p>

<p>master_last_io_seconds_ago = <code>/opt/redis/bin/redis-cli info | grep master_last_io_seconds_ago</code>.split(&lsquo;:&rsquo;).last.to_i rescue -1</p>

<p>status = &ldquo;A-Ok!&rdquo;
if master_last_io_seconds_ago &lt; 0 || master_last_io_seconds_ago >= options[:critical].to_i
  status = :critical
elsif master_last_io_seconds_ago >= options[:warning].to_i
  status = :warning
end</p>

<p>status_detail = master_last_io_seconds_ago == -1 ? &lsquo;ERROR&rsquo; : &ldquo;#{ master_last_io_seconds_ago.to_s }s&rdquo;
puts &ldquo;#{status.to_s.upcase} &ndash; replication lag: #{status_detail}&rdquo;</p>

<p>if status == :critical
  exit(2)
elsif status == :warning
  exit(1)
end
```</p>

<p>I stole this monitor from <a href="http://blog.winfieldpeterson.com/2012/12/13/monitoring-redis-replication-in-nagios/">here</a> but as you can tell the <code>redis-cli</code> is edited and the default status too.  <a href="https://twitter.com/miah_">Miah</a>&rsquo;s <a href="https://github.com/miah/chef-redis">cookbook</a> is great, works like a charm, but it puts the <code>redis-cli</code> in <code>/opt/redis/bin/</code>.</p>

<p>As a side note: I even put in a <a href="https://github.com/miah/chef-redis/pull/55">PR</a> to update to 2.6.16, because of this project.  I ran all the <a href="https://github.com/opscode/test-kitchen">test-kitchen</a> tests and it passed like a charm.  I actually learned about <a href="https://github.com/sstephenson/bats">bats</a> in the process, and honestly I&rsquo;m pretty damn impressed with something so straight forward.  Because serverspec fulfills my requirements at the moment, I don&rsquo;t have to use it; but I like the idea of having it in my back pocket.  The replication between master and slave seems extremely important, so this monitor has been a god sent.  I never have seen it spike over 45 seconds, but then the next check pop back to &lt;3 seconds.</p>

<p>The second monitor I wrote was this:
```bash</p>

<h1>!/bin/bash</h1>

<p>stateid=
LAST_SYNC_HUMAN=<code>/opt/redis/bin/redis-cli -h $1 info | grep rdb_last_save_time | awk -F : {'print $2'} | xargs -I {} date -d @{}</code>
LAST_SYNC=<code>/opt/redis/bin/redis-cli -h $1 info | grep rdb_last_save_time | awk -F : {'print $2'} | tr -d '\r'</code>
LAST_15MIN=<code>date -d '15 minutes ago' +%s</code>
LAST_20MIN=<code>date -d '20 minutes ago' +%s</code></p>

<p>if [ &ldquo;${LAST_15MIN}&rdquo; -lt &ldquo;${LAST_SYNC}&rdquo; ];
  then
  echo Sync has happened in the last 15 mins or less at ${LAST_SYNC_HUMAN}
  stateid=0
elif [ &ldquo;${LAST_15MIN}&rdquo; -ge &ldquo;${LAST_SYNC}&rdquo; ] &amp;&amp; [ &ldquo;${LAST_20MIN}&rdquo; -lt &ldquo;${LAST_SYNC}&rdquo; ];
  then
  echo Sync happened a little longer than we would like, the last at ${LAST_SYNC_HUMAN}
  stateid=1
elif [ &ldquo;${LAST_20MIN}&rdquo; -ge &ldquo;${LAST_SYNC}&rdquo; ];
  then
  echo Sync took over 20 mins, something might be wrong, the last sync happened at ${LAST_SYNC_HUMAN}
  stateid=2
fi
exit $stateid
```
This monitor I took from my typical <a href="https://github.com/jjasghar/scripts/blob/master/nagios_check_generic_template.sh">bash nagios template</a> and added the error states.  It seems like the .rdb file should always be in &ldquo;close&rdquo; proximity to the last write of to slave, and it would be nice to be alarmed about it if it went out of wack.  From what I&rsquo;ve seen it&rsquo;s never more than 1 or 2 minutes behind; so this worked out.  Writing a monitor for something and never seeing it fire till there is a real problem, that&rsquo;s a great place to be in.</p>

<h2>Non-nagios monitoring</h2>

<p>I started looking around for some type of dashboard to get some visual data about the redis instance.  It turns out there is a TON of these bastards, from a paid product like <a href="https://scoutapp.com/plugin_urls/271-redis-monitoring">Scout</a> to <a href="https://github.com/junegunn/redis-stat">redis-stat</a>.  I picked redis-stat because well, it&rsquo;s un-intrusive and fast.  I have it polling against my master slave on two instances of the gem running, and it&rsquo;s really nice to have a easily digestible view of the health of it.  I have noticed that it has doubled up the info because of the syncing, so be warned, you probably should run it via just the master and then maybe put all the slaves on one? (I&rsquo;m still trying to figure this one out.)</p>

<p>If you do read this and have good suggestions please through them my <a href="http://jjasghar.github.io/about/">way</a>, the <code>INFO</code> command gives you a lot of data, and redis-stat doesn&rsquo;t store anything so treading over time isn&rsquo;t an option. I was thinking about putting some of this data in ganglia, (another favorite of mine) but to have something just redis focused seems like the correct move here.</p>

<hr />

<p>So, so far these is the monitors that I&rsquo;m using for my new master slave set up.  My next challenge is creating the VIP in front of the master slave, and have a &ldquo;hot fail over.&rdquo; This is going to require some pretty interesting engineering; it&rsquo;s fun, but man the more I think about it the more it hurts my brain.  So I haven&rsquo;t actually talked about the migration yet either.  From what I&rsquo;ve understood it seems that 2.4.16 is actually <em>inside</em> 2.6.16, so if I get this VIP in front of this master slave then fail over to the slave turning off the read-only, this should be seamless. I need to do some testing; but that seems like the best course of action. For just the migration though, the &ldquo;hot fail over&rdquo; isn&rsquo;t required, but I want it to be in the fore-front of the design because I&rsquo;d rather be additive than have to rip out everything after we get up dated.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Nagios-status-rackspace]]></title>
    <link href="http://jjasghar.github.io/blog/2013/07/09/nagios-status-rackspace/"/>
    <updated>2013-07-09T15:05:00-05:00</updated>
    <id>http://jjasghar.github.io/blog/2013/07/09/nagios-status-rackspace</id>
    <content type="html"><![CDATA[<p>I posted a <a href="http://redd.it/1gefnf">this</a> on <a href="http://www.reddit.com/r/sysadmin">/r/sysadmin/</a> back on 6/15/13.  I wanted to put some context around why I created the nagios checks and why the <a href="https://status.rackspace.com/index/rss">RSS</a> after all that discussion still didn&rsquo;t fulfill my requirements.</p>

<p>The biggest problem I have with the RSS feed is that it is everything inside the rackspace status page.  As I said to <a href="http://www.reddit.com/user/rackerkev">/u/rackerkev</a>; as a customer in ORD I don&rsquo;t want to be paged or alerted when something in LON happens.  This seems be the default for the RSS feed, a water hose of what that status page says.</p>

<p>After our account manager suggested us to check <a href="http://status.rackspace.com">http://status.rackspace.com</a> a developer on my team asked if there was an automated way to check this.  I ran a quick <code>curl http://status.rackspace.com</code> and discovered it&rsquo;s flat html.  Boom, I had a way to get the data, I just needed a way to parse it.</p>

<p>I had a default nagios check template and all I had to do was put that <code>curl</code> in to parse it out.
``` bash</p>

<h1>!/bin/bash</h1>

<p>stateid=
SOMECMD=`echo &ldquo;something&rdquo;
SOMETHING=something</p>

<p>if [ &ldquo;${SOMECMD}&rdquo; == ${SOMETHING} ];
 then
   echo ${SOMETHING} is something
   stateid=0</p>

<h1>elif [  &ldquo;${SOMECMD}&rdquo; == ${SOMETHING} ];</h1>

<h1>then</h1>

<h1>echo This is a Warning</h1>

<h1>stateid=1</h1>

<p>elif [ &ldquo;${SOMECMD}&rdquo; != ${SOMETHING} ];
 then
   echo Something is broken!
   stateid=2
 fi
exit $stateid
```
I don&rsquo;t think this actually works, but hell you get the point.</p>

<p>So with some patience using <code>sed</code> and <code>grep</code> I was able to start parsing out the data for my back ends specifically.  I ended up parsing out each section so you could have London Next-Gen and Rackconnect General.  I had a couple posts about &ldquo;You should write it as one script and then add flags or variables at the end.&rdquo; I disagree, I wrote this so it could be dropped in nagios, straight forward install with little to no overhead.  As long as you have <code>curl</code> installed and write the command stanza, like my suggestion in the <a href="https://github.com/jjasghar/nagios-status-rackspace/blob/master/README.md">README.md</a> you should be off to the races.</p>

<p>Now something interesting I learned posting these checks.  The quote that says &ldquo;rackspace only updates the status page if enough customers complain about some problem some place&rdquo; is true.  There is no automated update to the status page, it requires human intervention to update.  When I first heard of the status page, I like most though it was programmatic way to see into rackspace infrastructure.  This makes me a sad panda; and as I have learned the best way to get anything done with rackspace is to call yell and yell more.</p>
]]></content>
  </entry>
  
</feed>
